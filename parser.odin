package ini

import "core:strings"
import "core:fmt"
import "core:log"

// The parser reads the list of tokens generated by the lexer and converts them into an ini.Config
Parser :: struct {
    pos: int,
    tokens: [dynamic]Token,
    config: ^Config,
    section: ^Config,
}

// Creates a new parser with the given token list and config then returns a pointer to it.
new_parser :: proc(tokens: [dynamic]Token, config: ^Config) -> ^Parser {
    if config == nil {
        log.errorf("Provided ^Config is nil. Returning nil.")
        return nil
    }

    log.debugf("Creating parser with given token array of %d tokens", len(tokens))

    p := new(Parser)
    p.pos = 0
    p.tokens = tokens
    p.config = config
    p.section = nil
    return p
}

// Parses the tokens into a config struct
parse :: proc(p: ^Parser) {
    if p == nil {
        log.errorf("Provided ^Parser is nil. Cannot parse. Returning.")
        return
    }

    t: Token
    for p.pos < len(p.tokens) {
        t = p.tokens[p.pos]

        #partial switch t.type {
        case .SECTION_LEFT: parse_section(p)
        case .IDENTIFIER: parse_key(p)
        case .COMMENT: p.pos += 1 // TODO Add comments to config?
        case .EOL: p.pos += 1
        case .EOF:
            log.debugf("EOF found at position %d. Finished parsing.", p.pos+1)
            return
        case:
            log.errorf("Unexpected token: '%s' (%v) @%d:%d. Ignoring.", t.value, t.type, t.line, t.col)
            skip_line(p, p.tokens[p.pos].line)
            p.pos += 1
        }
    }
}

// Parses a "key = value" statement.
parse_key :: proc(p: ^Parser) {
    key := strings.clone(p.tokens[p.pos].value)
    p.pos += 1

    if p.tokens[p.pos].type != .DELIMITER {
        log.errorf(
            "Expected %v ('%s') but found %v ('%s'). Cannot recover value of key '%s'. This value will be missing.",
            TokenType.DELIMITER,
            Options.Symbols.Delimiter,
            p.tokens[p.pos].type,
            p.tokens[p.pos].value,
            key
        )
        delete(key)
        skip_line(p, p.tokens[p.pos].line)
        return
    }

    p.pos += 1
    // TODO(hrs) check for extra identifiers.
    // because of whitespace separating multiple identifiers, and that values could have spaces in them,
    // we should check if there any anymore identifiers until an EOL then stich the values of any we find together.
    value := strings.clone(p.tokens[p.pos].value)
    p.pos += 1

    if p.section == nil {
        log.debugf("Successfully parsed key '%s' with a value of '%s'", key, value)
        set(p.config, key, value)
    } else {
        log.debugf("Successfully parsed key '%s' with a value of '%s' in section '%s'", key, value, p.section.value)
        set(p.section, key, value)
    }
}

// Parses a [section] statement
parse_section :: proc(p: ^Parser) {
    p.pos += 1
    section_name := strings.clone(p.tokens[p.pos].value)
    p.pos += 1

    if p.tokens[p.pos].type != .SECTION_RIGHT {
        log.errorf(
            "Expected %v ('%s') but found %v ('%s').",
            TokenType.SECTION_RIGHT,
            Options.Symbols.SectionRight,
            p.tokens[p.pos].type,
            p.tokens[p.pos].value
        )
    }

    p.pos += 1
    if p.tokens[p.pos].type != .EOL {
        log.errorf(
            "Expected %v ('\n') but found %v ('%s').",
            TokenType.EOL,
            p.tokens[p.pos].type,
            p.tokens[p.pos].value
        )
        skip_line(p, p.tokens[p.pos].line)
        delete(section_name)
        return
    }

    p.pos += 1
    p.section = add_section(p.config, section_name)
}

// If an unrecoverable error occurs during parsing then the parser will opt to skip all the tokens on the current line.
// This prevents additional errors from spawning because of an error prior in the list of tokens.
skip_line :: proc(p: ^Parser, line: int) {
    unskipped_pos := p.pos
    for p.tokens[p.pos].type != .EOL && p.tokens[p.pos].type != .EOF {
        p.pos += 1
    }

    // No point warning about skipping tokens if we didn't skip any
    if unskipped_pos != p.pos {
        log.warnf("Attempted to prevent further errors on line %d by skipping %d token(s).", line, p.pos-unskipped_pos)
    }
}